# Capturing Causal Claims: A Fine-Tuned Text Mining Model for Extracting Causal Sentences from Social Science Papers
## Abstract:
**_keywords_**: causal text mining, social science, parameter efficient tuning, causal sentences dataset
## 1. Introduction:
Understanding causality is an integral part of social scientific research. Causality is implicitly assumed when the results of social science research are used to inform decisions in treatment, policy, parenting, or clinical practice (Busetti 2023). Causal relationships are also crucial from a theoretical point of view, as a hallmark of “strong theories” is that they provide causal explanations for phenomena of interest (Hedström and Ylikoski 2010). There are growing concerns over a “theory crisis” in the social sciences because many prevailing psychological theories are vague and non-specific with regard to causality, which makes it difficult to formulate testable hypotheses and impedes cumulative knowledge acquisition (Berkman and Wilson 2021, Sanbonmatsu, Cooley et al. 2021). Scholars have recognized the importance of developing good theories that go beyond mere descriptions of empirical patterns. Good theories elucidate the underlying causal mechanisms (Van de Ven 1989, Reiter 2017). As Pearl (2009) notes, understanding causality enables social scientists, practitioners, consultants, and policy makers to draw meaningful insights from research literature to prescribe empirically supported solutions and interventions. Causal assumptions play a key role in substantiating hypotheses and facilitating nuanced interpretations of findings, thus enriching scholarly discourse (Meehl 1990, Reiter 2017). Given the importance of causality, it is unfortunate that social scientists do not always explicitly discuss causality (Gross 2018). To take stock of the current state of causal thought within a specific body of literature, this paper introduces a text mining model that extracts causal claims from full text papers. By automating the effortful procedure of coding statements as causal versus non-causal, this method enables comprehensive systematic reviews of causal claims in (large) bodies of literature. Our work contributes by curating a tailored dataset for social science literature and fine-tuning a model to extract causal sentences. This approach effectively addresses the challenges posed by the often ambiguous language used in social science literature to express causality, thereby substantially improving the accuracy and reliability of causal claim extraction from scholarly documents.
### SUBSECTION
Given the importance of causal assumptions for theory and practice, investigating existing causal claims in the published social scientific literature is a promising new area of meta-scientific research. An overview of existing causal claims can inform theory development, justify practical applications, and strengthen the methodological foundations that guide future theory-testing research. Due to the emergence of advanced text mining methods there has been a recent surge of interest in qualitative (or quantitatively aided qualitative) research synthesis methods. For instance, the use of text mining methods can be used to inductively identify important themes and relationships within a corpus of literature (Van Lissa 2022). At present, there are some methods available to automatically extract causal claims from scientific text. A major shortcoming of existing techniques is that none have been developed with attention to the idiosyncrasies of social scientific writing.
### SUBSECTION
Existing techniques for causal claims extraction can be broadly categorized into three main groups: knowledge-based methods, statistical machine learning methods, and deep learning methods (Yang, Han et al. 2022). Knowledge-based methods rely on manually constructed rules, patterns, and domain expertise (Riaz and Girju 2013). While they are suitable for extracting straightforward causal relationships within single sentences, they require substantial human effort and struggle with implicit or complex cross-sentence causality. To define rules and patterns to recognize the nuanced connections between sentences, these methods must be meticulously crafted, demanding significant time and expertise. As an example of cross-sentence causality, consider the scenario where two distinct causes of divorce are mentioned in separate sentences: "Unfaithfulness is often cited as a leading cause of divorce. Meanwhile, financial stress is identified as another significant contributor."(Yang, Han et al. 2022)
Statistical machine learning methods, leverage natural language processing (NLP) techniques and annotated corpora to extract features, which are then fed into machine learning algorithms. These methods offer more automation than knowledge-based approaches but sometimes  require labor-intensive feature-engineering. The third category, deep learning methods automatically learn condensed numerical representations of words, allowing for better representation learning and cross-domain portability (Yang, Han et al. 2022). Recurrent neural networks (RNNs), convolutional neural networks (CNNs), and graph convolutional networks (GCNs) are among the deep learning models commonly employed for causal relation extraction (Zhao, Wang et al. 2021). In the progression of NLP techniques, the advent of BERT (Bidirectional Encoder Representations from Transformers) introduced a paradigm shift towards models equipped with transformer mechanisms. These models, by design, excel in deciphering the context of words within sentences, showcasing a marked improvement over prior methodologies (Devlin, Chang et al. 2018). The advancement of transformer models not only highlights the deficiencies of earlier approaches in understanding language nuances; it has also shown superior performance in benchmark evaluations, surpassing previous knowledge-based and statistical methods in the precision and recall of extracted causal relationships (Tan, Zuo et al. 2022).
Transformer models are trained on a large corpus of text, and the resulting model is called the pre-trained model. These pre-trained models can then be fine-tuned on specific downstream tasks and datasets. This pre-training feature allows for fine-tuning on specialized tasks using considerably smaller datasets, highlighting their adaptability and effectiveness across a wide range of applications (Chen and Zhang 2021). However, a notable concern is the substantial computational resources required, which has been somewhat alleviated by emerging techniques such as Parameter-Efficient tuning. This technique optimizes a small portion of model parameters while keeping the rest fixed, significantly reducing computation and storage costs (Ding, Qin et al. 2023). This development offers a promising way to harness the computational power of these models more efficiently. Given their profound understanding of context and nuanced capabilities, this study aims to employ transformer’s models to leverage their strengths in addressing challenges posed by limited data resources.
### SUBSECTION 
The extraction of causal relations from unstructured text poses significant challenges due to the complexity and variability of human language, as well as the diverse patterns used to represent causality. The problem is compounded because causal sentence extraction techniques developed in one scientific field often perform worse when applied in other fields;  a problem known as domain shift bias (Moghimifar, Haffari et al. 2020). Within the scope of social sciences, the challenges are intensified due to a pervasive reluctance to employ explicit causal language, a trend not commonly observed in other disciplines. This hesitation leads to vague and indirect expressions about causality, complicating the task of identifying causal connections. For instance, terms like "explain", "influence", and "predict", hint at causality but remain ambiguous about the actual nature of the relationships involved. This vagueness is a significant hurdle for causal sentence detection. This ambiguity is further compounded by the prevalent use of hedging and “weasel words” in scientific writing, which introduce uncertainty and obscure facts, often leading to misinterpretation or misrepresentation of the causal links being studied. This practice not only impedes clear understanding but also hampers the advancement of knowledge in these fields, as it fosters a culture of truthiness, where personal beliefs or assumptions are presented as facts without adequate evidence (Ott 2018, Grosz, Rohrer et al. 2020).
### SUBSECTION (Aims of this paper)
To address the challenges of ambiguity and lack of precision when extracting causal claims from social science text, this study set out to develop a fine-tuned model specifically designed for classifying causal and non-causal sentences in social science literature. Several candidate models were considered, including existing solutions and newly developed models based on prior research. This study further sets out to curate a dataset tailored specifically to the domain of social science, comprising 500 causal and 500 non-causal sentences extracted from the Cooperation Databank (CoDa); a comprehensive annotated archive of all studies on human cooperation(Spadaro, Tiddi et al. 2022). This dataset was also used to benchmark the performance of the candidate models. This paper contributes a manually curated dataset and fine-tuned causality detection model, which have the potential to significantly enhance the detection and analysis of causal claims in social scientific publications. Furthermore, the annotated data and tuned model serve as a foundation for further advancements in the extraction and analysis of causal sentences from the vast body of social science literature.
Following the fine-tuning of our model, we will address the following research questions:
- a) Which model works better in extracting causal language sentences from social science context? 
- b) Does fine-tuning models using domain specific training data confer a performance advantage?
- c) Does the performance of general causal sentence extraction models generalize to data from the context of social scientific literature?
- d) Does fine-tuning on social science data improve performance on general datasets?
# 2. Method
In this section we are going to explain the steps that are done for training our model. As we are going to curate our domain specific causal and non-causal claims dataset, firstly we should provide a definition of causal language.
## 2.1 Definition of Causal Language
Causal language involves clauses or phrases where one event, state, action, or entity is explicitly portrayed as influencing another. Linguistic cues of causation abound, with causative verbs (such as 'increase', 'decrease', or 'improve') often denoting a strong causal relationship. Conjunctions such as 'because', 'due to', and 'since' are commonly used to express causality. It is noteworthy that academic writers, in an endeavor to make their research both accessible and compelling, might occasionally employ language that overstates causality (Thapa, Visentin et al. 2020).

```
Table 1
+--------+---------+------+----------+---------+
| Models | RoBERTa | BERT | LLAMA-7b | MISTRAL |
+--------+---------+------+----------+---------+
|        |         |      |          |         |
|    F   +---------+------+----------+---------+
|        |         |      |          |         |
+--------+---------+------+----------+---------+
|        |         |      |          |         |
+--------+---------+------+----------+---------+
```
