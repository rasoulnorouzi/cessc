# Capturing Causal Claims: A Fine-Tuned Text Mining Model for Extracting Causal Sentences from Social Science Papers
## Abstract:
**_keywords_**: causal text mining, social science, parameter efficient tuning, causal sentences dataset
## 1. Introduction:
Understanding causality is an integral part of social scientific research. Causality is implicitly assumed when the results of social science research are used to inform decisions in treatment, policy, parenting, or clinical practice (Busetti, 2023). Causal relationships are also crucial from a theoretical point of view, as a hallmark of “strong theories” is that they provide causal explanations for phenomena of interest (Hedström & Ylikoski, 2010). There are growing concerns over a “theory crisis” in the social sciences because many prevailing psychological theories are vague and non-specific with regard to causality, which makes it difficult to formulate testable hypotheses and impedes cumulative knowledge acquisition (Berkman & Wilson, 2021; Sanbonmatsu et al., 2021). Scholars have recognized the importance of developing good theories that go beyond mere descriptions of empirical patterns. Good theories elucidate the underlying causal mechanisms (Reiter, 2017; Van De Ven, 1989). As Pearl (2009) notes, understanding causality enables social scientists, practitioners, consultants, and policy makers to draw meaningful insights from research literature to prescribe empirically supported solutions and interventions. Causal assumptions play a key role in substantiating hypotheses and facilitating nuanced interpretations of findings, thus enriching scholarly discourse (Meehl, 1990; Reiter, 2017). Given the importance of causality, it is unfortunate that social scientists do not always explicitly discuss causality (Gross, 2018). To take stock of the current state of causal thought within a specific body of literature, this paper introduces a text mining model that extracts causal claims from full text papers. By automating the effortful procedure of coding statements as causal versus non-causal, this method enables comprehensive systematic reviews of causal claims in (large) bodies of literature. Our work contributes by curating a tailored dataset for social science literature and fine-tuning a model to extract causal sentences. This approach effectively addresses the challenges posed by the often ambiguous language used in social science literature to express causality, thereby substantially improving the accuracy and reliability of causal claim extraction from scholarly documents.
### 1.1 Why Care About Causality?
Given the importance of causal assumptions for theory and practice, investigating existing causal claims in the published social scientific literature is a promising new area of meta-scientific research. An overview of existing causal claims can inform theory development, justify practical applications, and strengthen the methodological foundations that guide future theory-testing research. Due to the emergence of advanced text mining methods, there has been a recent surge of interest in qualitative (or quantitatively aided qualitative) research synthesis methods. For instance, the use of text mining methods can be used to inductively identify important themes and relationships within a corpus of literature (Van Lissa, 2022). At present, there are some methods available to automatically extract causal claims from scientific text. A major shortcoming of existing techniques is that none have been developed with attention to the idiosyncrasies of social scientific writing.

### 1.2 Prior Work in Causality Detection

Existing techniques for causal claims extraction can be broadly categorized into three main groups: knowledge-based methods, statistical machine learning methods, and deep learning methods (Yang et al., 2022). Knowledge-based methods rely on manually constructed rules, patterns, and domain expertise (Riaz & Girju, 2013). While they are suitable for extracting straightforward causal relationships within single sentences, they require substantial human effort and struggle with implicit or complex cross-sentence causality. To define rules and patterns to recognize the nuanced connections between sentences, these methods must be meticulously crafted, demanding significant time and expertise. As an example of cross-sentence causality, consider the scenario where two distinct causes of divorce are mentioned in separate sentences: "Unfaithfulness is often cited as a leading cause of divorce. Meanwhile, financial stress is identified as another significant contributor." (Yang et al., 2022).

Statistical machine learning methods, leverage natural language processing (NLP) techniques and annotated corpora to extract features, which are then fed into machine learning algorithms. These methods offer more automation than knowledge-based approaches but sometimes  require labor-intensive feature-engineering. The third category, deep learning methods automatically learn condensed numerical representations of words, allowing for better representation learning and cross-domain portability (Yang et al., 2022). Recurrent neural networks (RNNs), convolutional neural networks (CNNs), and graph convolutional networks (GCNs) are among the deep learning models commonly employed for causal relation extraction (Zhao et al., 2021). In the progression of NLP techniques, the advent of BERT (Bidirectional Encoder Representations from Transformers) introduced a paradigm shift towards models equipped with transformer mechanisms. These models, by design, excel in deciphering the context of words within sentences, showcasing a marked improvement over prior methodologies (Kenton & Toutanova, 2019). The advancement of transformer models not only highlights the deficiencies of earlier approaches in understanding language nuances; it has also shown superior performance in benchmark evaluations, surpassing previous knowledge-based and statistical methods in the precision and recall of extracted causal relationships (Tan et al., 2023).

Transformer models are trained on a large corpus of text, and the resulting model is called the pre-trained model. These pre-trained models can then be fine-tuned on specific downstream tasks and datasets. This pre-training feature allows for fine-tuning on specialized tasks using considerably smaller datasets, highlighting their adaptability and effectiveness across a wide range of applications (Chen & Zhang, 2021). However, a notable concern is the substantial computational resources required, which has been somewhat alleviated by emerging techniques such as Parameter-Efficient tuning. This technique optimizes a small portion of model parameters while keeping the rest fixed, significantly reducing computation and storage costs (Ding et al., 2023). This development offers a promising way to harness the computational power of these models more efficiently. Given their profound understanding of context and nuanced capabilities, this study aims to employ transformer’s models to leverage their strengths in addressing challenges posed by limited data resources.

### 1.3 Causality Detection in Social Science

The extraction of causal relations from unstructured text poses significant challenges due to the complexity and variability of human language, as well as the diverse patterns used to represent causality. The problem is compounded because causal sentence extraction techniques developed in one scientific field often perform worse when applied in other fields; a problem known as domain shift bias (Moghimifar et al., 2020). Within the scope of social sciences, the challenges are intensified due to a pervasive reluctance to employ explicit causal language, a trend not commonly observed in other disciplines. This hesitation leads to vague and indirect expressions about causality, complicating the task of identifying causal connections. For instance, terms like "explain", "influence", and "predict", hint at causality but remain ambiguous about the actual nature of the relationships involved. This vagueness is a significant hurdle for causal sentence detection. This ambiguity is further compounded by the prevalent use of hedging and “weasel words” in scientific writing, which introduce uncertainty and obscure facts, often leading to misinterpretation or misrepresentation of the causal links being studied. This practice not only impedes clear understanding but also hampers the advancement of knowledge in these fields, as it fosters a culture of truthiness, where personal beliefs or assumptions are presented as facts without adequate evidence (Grosz et al., 2020; Ott, 2018).

### 1.4 The Present Study

To address the challenges of ambiguity and lack of precision when extracting causal claims from social science text, this study set out to develop a fine-tuned model specifically designed for classifying causal and non-causal sentences in social science literature. Several candidate models were considered, including existing solutions and newly developed models based on prior research. This study further sets out to curate a dataset tailored specifically to the domain of social science, comprising 510 causal and 510 non-causal sentences extracted from the Cooperation Databank (CoDa); a comprehensive annotated archive of all studies on human cooperation (Spadaro et al., 2022). This dataset was also used to benchmark the performance of the candidate models. This paper contributes a manually curated dataset and fine-tuned causality detection model, which have the potential to significantly enhance the detection and analysis of causal claims in social scientific publications. Furthermore, the annotated data and tuned model serve as a foundation for further advancements in the extraction and analysis of causal sentences from the vast body of social science literature.

Following the fine-tuning of our model, we will address the following research questions:

- a) Which model works better in extracting causal language sentences from social science context?
- b) Does fine-tuning models using domain specific training data confer a performance advantage?
- c) Does the performance of general causal sentence extraction models generalize to data from the context of social scientific literature?
- d) Does the curated dataset for social science contribute to increase the performance of general and domain specific models?
## 2. Method

In this section we are going to explain the steps that are done for training our model. As we are going to curate our domain-specific causal and non-causal claims dataset, firstly we will define the causal language that we used for the data curation process.
### 2.2.1 General Purpose Dataset
We drew upon earlier work that introduced six datasets for analyzing causal sentences (Tan et al., 2023). However, as the Penn Discourse Treebank (PDTB) dataset is not openly available, it was excluded from our study. The following is a summary of the datasets that were utilized to construct the combined corpus:

**AltLex:** Annotated causal language utilizing alternative lexicalizations within single sentences from news articles. However, it has limitations including a small size, exclusion of implicit signals, and consideration solely of intra-sentence relations.

**BECAUSE 2.0:** Annotations of cause, effect, and connective spans based on Construction Grammar principles within single sentences from diverse sources. Its limitations comprise a modest size and omission of inter-sentence relations.

**CausalTimeBank (CTB):** Explicit causal relation annotations between events within the TempEval-3 corpus. It focuses solely on annotating events and disregards contextual information.

**EventStoryLine (ESL):** Annotations of both explicit and implicit causal relations between events in the Event Coreference Bank. It shares similar limitations with CTB in terms of event-centric annotation.

**SemEval 2010 Task 8:** Originally annotated for classifying semantic relations between noun phrases, with limitations including absence of contextual argument information and annotation restricted to inter-sentence relations.

Table 1 displays the number of causal and non-causal samples for both training and validation sets of each dataset separately. We should point out that the number of samples and its balance report is before preprocessing, as there were many duplicated samples in them.

Table 1- Five open-source datasets were utilized in this research.
<table style="border-collapse:collapse;border-spacing:0" class="tg"><thead><tr><th style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal">Corpus</th><th style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal">Split</th><th style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal">Causal</th><th style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal">Non-Causal</th><th style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal">Sample Causal Sentence</th></tr></thead><tbody><tr><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal" rowspan="2"><br>AltLex</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">training</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">326</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">285</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal" rowspan="2">In a panic, he removed his mask,<br>inhaling a large amount of<br>phosgene gas which <span style="font-weight:bold">resulted in</span> <br>his death 72 hours later.</td></tr><tr><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">test</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">130</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">286</td></tr><tr><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal" rowspan="2"><br><br>BECAUSE 2.0</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">training</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">473</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">107</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal" rowspan="2"><span style="font-weight:bold">Thanks to</span> the fast action of<br>the Federal Reserve in <br>cooperation with the SEC<br>and the Treasury, we dodged a <br>bullet when Bear <br>Stearns collapsed.</td></tr><tr><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">test</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">15</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">4</td></tr><tr><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal" rowspan="2"><br>CausalTimeBank(CTB)</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">training</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">718</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">2599</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal" rowspan="2">In space, some say female pilots <br>were held up until now <span style="font-weight:bold">by </span>the lack <br>of piloting opportunities for them <br>in the military.</td></tr><tr><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">test</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">100</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">392</td></tr><tr><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:center;vertical-align:top;word-break:normal" rowspan="2"><br>EventStoryLine (ESL)</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">training</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">9146</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">8268</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal" rowspan="2"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">3 dead </span><span style="font-weight:700;font-style:normal;text-decoration:none;color:#000;background-color:transparent">after</span><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent"> protesters torch Greek </span><br><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">bank Three people died in a burning </span><br><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">bank as tens of thousands of protesters </span><br><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">took to the streets of Athens during a </span><br><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">general strike over the Greek </span><br><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">government's planned spending cuts.</span></td></tr><tr><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">test</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">894</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">1073</td></tr><tr><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal" rowspan="2"><br>SemEval 2010 Task 8</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">training</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">1003</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">6997</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal" rowspan="2">The current view is that the chronic <br>inflammation in the distal part of the <br>stomach caused by Helicobacter <br>pylori infection <span style="font-weight:bold">results in</span> an increased <br>acid production from the non-infected <br>upper corpus region of the stomach.</td></tr><tr><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">test</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">328</td><td style="border-color:inherit;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;text-align:left;vertical-align:top;word-break:normal">2389</td></tr></tbody></table>

We combined the training and test sets of these datasets to make a general-purpose dataset. Initially, it contained a significant amount of duplicate data, with 29,922 training and 5,611 test samples. After removing these duplicates, the dataset was reduced to 12,834 training and 3,679 test samples. The dataset was highly imbalanced (9,954 were causal and 2,880 were non-causal), posing a risk of bias during model fine-tuning. To counter this, we applied an undersampling technique resulting in a balanced general-purpose dataset with 5,760 samples, equally divided between causal and non-causal sentences. Although the test set was imbalanced, with 3,070 non-causal and 609 causal sentences, we chose to leave it as is. This decision was made to ensure that the test set accurately reflects real-world scenarios, providing a true measure of the model's performance. The training set was then randomly split, assigning 20 percent for validation and the remainder for training.
### 2.2.2 Curated Social Science Dataset
We manually curated an additional dataset aimed at understanding the use of causal language in social science literature based on The Cooperation Databank, a collection of all papers dedicated to game theory applications within social science (Spadaro et al., 2022). From this dataset, 2,590 articles were converted into raw text using the Grobid library in Python and subsequently segmented at the sentence level (Lopez, 2009). 

Following conversion, a post-processing stage corrected common errors arising during PDF-to-text translation. These errors typically involve misinterpretations of similar characters, such as "0" and "O," "b" and "6," or incorrect joining or splitting of letters.

The lead author labeled sentences using the Doccano web annotation tool (Nakayama et al., 2018). Sentences were cataloged as either causal, non-causal, or ambiguous. Instances marked as ambiguous (117 of 1010 sentences; 11.58%) were subsequently reviewed by all authors. Inter-rater agreement was estimated using Fleiss' Kappa index (Fleiss, 1971), resulting in $Kappa = 0.76$, denoting 'substantial' agreement. For those samples where consensus was elusive, a majority voting method was employed to finalize the labels. Ultimately, a number of 508 causal and 502 non-causal sentences were curated.
This dataset is balanced, and we divided it into 70 percent for training, 10 percent for validation, and 20 percent for testing.






## References

1. Berkman, E. T., & Wilson, S. M. (2021). So useful as a good theory? The practicality crisis in (social) psychological theory. Perspectives on Psychological Science, 16(4), 864–874.
2. Busetti, S. (2023). Causality is good for practice: Policy design and reverse engineering. Policy Sciences, 56(2), 419–438. https://doi.org/10.1007/s11077-023-09493-7
3. Chen, Z., & Zhang, Y. (2021). Better few-shot text classification with pre-trained language model. Artificial Neural Networks and Machine Learning–ICANN 2021: 30th International Conference on Artificial Neural Networks, Bratislava, Slovakia, September 14–17, 2021, Proceedings, Part II 30, 537–548.
4. Ding, N., Qin, Y., Yang, G., Wei, F., Yang, Z., Su, Y., Hu, S., Chen, Y., Chan, C.-M., Chen, W., Yi, J., Zhao, W., Wang, X., Liu, Z., Zheng, H.-T., Chen, J., Liu, Y., Tang, J., Li, J., & Sun, M. (2023). Parameter-efficient fine-tuning of large-scale pre-trained language models. Nature Machine Intelligence, 5(3), 220–235. https://doi.org/10.1038/s42256-023-00626-4
5. Gross, N. (2018). The Structure of Causal Chains. Sociological Theory, 36(4), 343–367. https://doi.org/10.1177/0735275118811377
6. Grosz, M. P., Rohrer, J. M., & Thoemmes, F. (2020). The taboo against explicit causal inference in nonexperimental psychology. Perspectives on Psychological Science, 15(5), 1243–1255.
7. Hedström, P., & Ylikoski, P. (2010). Causal Mechanisms in the Social Sciences. Annual Review of Sociology, 36(1), 49–67. https://doi.org/10.1146/annurev.soc.012809.102632
8. Kenton, J. D. M.-W. C., & Toutanova, L. K. (2019). Bert: Pre-training of deep bidirectional transformers for language understanding. Proceedings of naacL-HLT, 1, 2.
9. Meehl, P. E. (1990). Appraising and Amending Theories: The Strategy of Lakatosian Defense and Two Principles that Warrant It. Psychological Inquiry, 1(2), 108–141. https://doi.org/10.1207/s15327965pli0102_1
10. Moghimifar, F., Haffari, G., & Baktashmotlagh, M. (2020). Domain adaptative causality encoder. arXiv Preprint arXiv:2011.13549.
11. Ott, D. E. (2018). Hedging, Weasel Words, and Truthiness in Scientific Writing. JSLS : Journal of the Society of Laparoendoscopic Surgeons, 22(4), e2018.00063. https://doi.org/10.4293/JSLS.2018.00063
12. Pearl, J. (2009). Causal inference in statistics: An overview.
13. Reiter, B. (2017). Theory and methodology of exploratory social science research.
14. Riaz, M., & Girju, R. (2013). Toward a better understanding of causality between verbal events: Extraction and analysis of the causal power of verb-verb associations. Proceedings of the SIGDIAL 2013 Conference, 21–30.
15. Sanbonmatsu, D. M., Cooley, E. H., & Butner, J. E. (2021). The Impact of Complexity on Methods and Findings in Psychological Science. Frontiers in Psychology, 11, 580111. https://doi.org/10.3389/fpsyg.2020.580111
16. Spadaro, G., Tiddi, I., Columbus, S., Jin, S., Ten Teije, A., Team, C., & Balliet, D. (2022). The Cooperation Databank: Machine-readable science accelerates research synthesis. Perspectives on Psychological Science, 17(5), 1472–1489.
17. Tan, F. A., Zuo, X., & Ng, S.-K. (2023). UniCausal: Unified Benchmark and Repository for Causal Text Mining (arXiv:2208.09163). arXiv. http://arxiv.org/abs/2208.09163
18. Van De Ven, A. H. (1989). Nothing Is Quite So Practical as a Good Theory. Academy of Management Review, 14(4), 486–489. https://doi.org/10.5465/amr.1989.4308370
19. Van Lissa, C. J. (2022). Mapping Phenomena Relevant to Adolescent Emotion Regulation: A Text-Mining Systematic Review. Adolescent Research Review, 7(1), 127–139. https://doi.org/10.1007/s40894-021-00160-7
20. Yang, J., Han, S. C., & Poon, J. (2022). A survey on extraction of causal relations from natural language text. Knowledge and Information Systems, 64(5), 1161–1186. https://doi.org/10.1007/s10115-022-01665-w
21. Zhao, D., Wang, J., Lin, H., Wang, X., Yang, Z., & Zhang, Y. (2021). Biomedical cross-sentence relation extraction via multihead attention and graph convolutional networks. Applied Soft Computing, 104, 107230. https://doi.org/10.1016/j.asoc.2021.107230