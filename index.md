# Capturing Causal Claims: A Fine-Tuned Text Mining Model for Extracting Causal Sentences from Social Science Papers
## Abstract:
**_keywords_**: causal text mining, social science, parameter efficient tuning, causal sentences dataset
## 1. Introduction:
Understanding causality is an integral part of social scientific research. Causality is implicitly assumed when the results of social science research are used to inform decisions in treatment, policy, parenting, or clinical practice (Busetti, 2023). Causal relationships are also crucial from a theoretical point of view, as a hallmark of “strong theories” is that they provide causal explanations for phenomena of interest (Hedström & Ylikoski, 2010). There are growing concerns over a “theory crisis” in the social sciences because many prevailing psychological theories are vague and non-specific with regard to causality, which makes it difficult to formulate testable hypotheses and impedes cumulative knowledge acquisition (Berkman & Wilson, 2021; Sanbonmatsu et al., 2021). Scholars have recognized the importance of developing good theories that go beyond mere descriptions of empirical patterns. Good theories elucidate the underlying causal mechanisms (Reiter, 2017; Van De Ven, 1989). As Pearl (2009) notes, understanding causality enables social scientists, practitioners, consultants, and policy makers to draw meaningful insights from research literature to prescribe empirically supported solutions and interventions. Causal assumptions play a key role in substantiating hypotheses and facilitating nuanced interpretations of findings, thus enriching scholarly discourse (Meehl, 1990; Reiter, 2017). Given the importance of causality, it is unfortunate that social scientists do not always explicitly discuss causality (Gross, 2018). To take stock of the current state of causal thought within a specific body of literature, this paper introduces a text mining model that extracts causal claims from full text papers. By automating the effortful procedure of coding statements as causal versus non-causal, this method enables comprehensive systematic reviews of causal claims in (large) bodies of literature. Our work contributes by curating a tailored dataset for social science literature and fine-tuning a model to extract causal sentences. This approach effectively addresses the challenges posed by the often ambiguous language used in social science literature to express causality, thereby substantially improving the accuracy and reliability of causal claim extraction from scholarly documents.
### 1.1 Why Care About Causality?
Given the importance of causal assumptions for theory and practice, investigating existing causal claims in the published social scientific literature is a promising new area of meta-scientific research. An overview of existing causal claims can inform theory development, justify practical applications, and strengthen the methodological foundations that guide future theory-testing research. Due to the emergence of advanced text mining methods, there has been a recent surge of interest in qualitative (or quantitatively aided qualitative) research synthesis methods. For instance, the use of text mining methods can be used to inductively identify important themes and relationships within a corpus of literature (Van Lissa, 2022). At present, there are some methods available to automatically extract causal claims from scientific text. A major shortcoming of existing techniques is that none have been developed with attention to the idiosyncrasies of social scientific writing.

### 1.2 Prior Work in Causality Detection

Existing techniques for causal claims extraction can be broadly categorized into three main groups: knowledge-based methods, statistical machine learning methods, and deep learning methods (Yang et al., 2022). Knowledge-based methods rely on manually constructed rules, patterns, and domain expertise (Riaz & Girju, 2013). While they are suitable for extracting straightforward causal relationships within single sentences, they require substantial human effort and struggle with implicit or complex cross-sentence causality. To define rules and patterns to recognize the nuanced connections between sentences, these methods must be meticulously crafted, demanding significant time and expertise. As an example of cross-sentence causality, consider the scenario where two distinct causes of divorce are mentioned in separate sentences: "Unfaithfulness is often cited as a leading cause of divorce. Meanwhile, financial stress is identified as another significant contributor." (Yang et al., 2022).

Statistical machine learning methods, leverage natural language processing (NLP) techniques and annotated corpora to extract features, which are then fed into machine learning algorithms. These methods offer more automation than knowledge-based approaches but sometimes  require labor-intensive feature-engineering. The third category, deep learning methods automatically learn condensed numerical representations of words, allowing for better representation learning and cross-domain portability (Yang et al., 2022). Recurrent neural networks (RNNs), convolutional neural networks (CNNs), and graph convolutional networks (GCNs) are among the deep learning models commonly employed for causal relation extraction (Zhao et al., 2021). In the progression of NLP techniques, the advent of BERT (Bidirectional Encoder Representations from Transformers) introduced a paradigm shift towards models equipped with transformer mechanisms. These models, by design, excel in deciphering the context of words within sentences, showcasing a marked improvement over prior methodologies (Kenton & Toutanova, 2019). The advancement of transformer models not only highlights the deficiencies of earlier approaches in understanding language nuances; it has also shown superior performance in benchmark evaluations, surpassing previous knowledge-based and statistical methods in the precision and recall of extracted causal relationships (Tan et al., 2023).

Transformer models are trained on a large corpus of text, and the resulting model is called the pre-trained model. These pre-trained models can then be fine-tuned on specific downstream tasks and datasets. This pre-training feature allows for fine-tuning on specialized tasks using considerably smaller datasets, highlighting their adaptability and effectiveness across a wide range of applications (Chen & Zhang, 2021). However, a notable concern is the substantial computational resources required, which has been somewhat alleviated by emerging techniques such as Parameter-Efficient tuning. This technique optimizes a small portion of model parameters while keeping the rest fixed, significantly reducing computation and storage costs (Ding et al., 2023). This development offers a promising way to harness the computational power of these models more efficiently. Given their profound understanding of context and nuanced capabilities, this study aims to employ transformer’s models to leverage their strengths in addressing challenges posed by limited data resources.

### 1.3 Causality Detection in Social Science

The extraction of causal relations from unstructured text poses significant challenges due to the complexity and variability of human language, as well as the diverse patterns used to represent causality. The problem is compounded because causal sentence extraction techniques developed in one scientific field often perform worse when applied in other fields; a problem known as domain shift bias (Moghimifar et al., 2020). Within the scope of social sciences, the challenges are intensified due to a pervasive reluctance to employ explicit causal language, a trend not commonly observed in other disciplines. This hesitation leads to vague and indirect expressions about causality, complicating the task of identifying causal connections. For instance, terms like "explain", "influence", and "predict", hint at causality but remain ambiguous about the actual nature of the relationships involved. This vagueness is a significant hurdle for causal sentence detection. This ambiguity is further compounded by the prevalent use of hedging and “weasel words” in scientific writing, which introduce uncertainty and obscure facts, often leading to misinterpretation or misrepresentation of the causal links being studied. This practice not only impedes clear understanding but also hampers the advancement of knowledge in these fields, as it fosters a culture of truthiness, where personal beliefs or assumptions are presented as facts without adequate evidence (Grosz et al., 2020; Ott, 2018).

### 1.4 The Present Study

To address the challenges of ambiguity and lack of precision when extracting causal claims from social science text, this study set out to develop a fine-tuned model specifically designed for classifying causal and non-causal sentences in social science literature. Several candidate models were considered, including existing solutions and newly developed models based on prior research. This study further sets out to curate a dataset tailored specifically to the domain of social science, comprising 510 causal and 510 non-causal sentences extracted from the Cooperation Databank (CoDa); a comprehensive annotated archive of all studies on human cooperation (Spadaro et al., 2022). This dataset was also used to benchmark the performance of the candidate models. This paper contributes a manually curated dataset and fine-tuned causality detection model, which have the potential to significantly enhance the detection and analysis of causal claims in social scientific publications. Furthermore, the annotated data and tuned model serve as a foundation for further advancements in the extraction and analysis of causal sentences from the vast body of social science literature.

Following the fine-tuning of our model, we will address the following research questions:

- a) Which model works better in extracting causal language sentences from social science context?
- b) Does fine-tuning models using domain specific training data confer a performance advantage?
- c) Does the performance of general causal sentence extraction models generalize to data from the context of social scientific literature?
- d) Does the curated dataset for social science contribute to increase the performance of general and domain specific models?


## References

1. Berkman, E. T., & Wilson, S. M. (2021). So useful as a good theory? The practicality crisis in (social) psychological theory. Perspectives on Psychological Science, 16(4), 864–874.
2. Busetti, S. (2023). Causality is good for practice: Policy design and reverse engineering. Policy Sciences, 56(2), 419–438. https://doi.org/10.1007/s11077-023-09493-7
3. Chen, Z., & Zhang, Y. (2021). Better few-shot text classification with pre-trained language model. Artificial Neural Networks and Machine Learning–ICANN 2021: 30th International Conference on Artificial Neural Networks, Bratislava, Slovakia, September 14–17, 2021, Proceedings, Part II 30, 537–548.
4. Ding, N., Qin, Y., Yang, G., Wei, F., Yang, Z., Su, Y., Hu, S., Chen, Y., Chan, C.-M., Chen, W., Yi, J., Zhao, W., Wang, X., Liu, Z., Zheng, H.-T., Chen, J., Liu, Y., Tang, J., Li, J., & Sun, M. (2023). Parameter-efficient fine-tuning of large-scale pre-trained language models. Nature Machine Intelligence, 5(3), 220–235. https://doi.org/10.1038/s42256-023-00626-4
5. Gross, N. (2018). The Structure of Causal Chains. Sociological Theory, 36(4), 343–367. https://doi.org/10.1177/0735275118811377
6. Grosz, M. P., Rohrer, J. M., & Thoemmes, F. (2020). The taboo against explicit causal inference in nonexperimental psychology. Perspectives on Psychological Science, 15(5), 1243–1255.
7. Hedström, P., & Ylikoski, P. (2010). Causal Mechanisms in the Social Sciences. Annual Review of Sociology, 36(1), 49–67. https://doi.org/10.1146/annurev.soc.012809.102632
8. Kenton, J. D. M.-W. C., & Toutanova, L. K. (2019). Bert: Pre-training of deep bidirectional transformers for language understanding. Proceedings of naacL-HLT, 1, 2.
9. Meehl, P. E. (1990). Appraising and Amending Theories: The Strategy of Lakatosian Defense and Two Principles that Warrant It. Psychological Inquiry, 1(2), 108–141. https://doi.org/10.1207/s15327965pli0102_1
10. Moghimifar, F., Haffari, G., & Baktashmotlagh, M. (2020). Domain adaptative causality encoder. arXiv Preprint arXiv:2011.13549.
11. Ott, D. E. (2018). Hedging, Weasel Words, and Truthiness in Scientific Writing. JSLS : Journal of the Society of Laparoendoscopic Surgeons, 22(4), e2018.00063. https://doi.org/10.4293/JSLS.2018.00063
12. Pearl, J. (2009). Causal inference in statistics: An overview.
13. Reiter, B. (2017). Theory and methodology of exploratory social science research.
14. Riaz, M., & Girju, R. (2013). Toward a better understanding of causality between verbal events: Extraction and analysis of the causal power of verb-verb associations. Proceedings of the SIGDIAL 2013 Conference, 21–30.
15. Sanbonmatsu, D. M., Cooley, E. H., & Butner, J. E. (2021). The Impact of Complexity on Methods and Findings in Psychological Science. Frontiers in Psychology, 11, 580111. https://doi.org/10.3389/fpsyg.2020.580111
16. Spadaro, G., Tiddi, I., Columbus, S., Jin, S., Ten Teije, A., Team, C., & Balliet, D. (2022). The Cooperation Databank: Machine-readable science accelerates research synthesis. Perspectives on Psychological Science, 17(5), 1472–1489.
17. Tan, F. A., Zuo, X., & Ng, S.-K. (2023). UniCausal: Unified Benchmark and Repository for Causal Text Mining (arXiv:2208.09163). arXiv. http://arxiv.org/abs/2208.09163
18. Van De Ven, A. H. (1989). Nothing Is Quite So Practical as a Good Theory. Academy of Management Review, 14(4), 486–489. https://doi.org/10.5465/amr.1989.4308370
19. Van Lissa, C. J. (2022). Mapping Phenomena Relevant to Adolescent Emotion Regulation: A Text-Mining Systematic Review. Adolescent Research Review, 7(1), 127–139. https://doi.org/10.1007/s40894-021-00160-7
20. Yang, J., Han, S. C., & Poon, J. (2022). A survey on extraction of causal relations from natural language text. Knowledge and Information Systems, 64(5), 1161–1186. https://doi.org/10.1007/s10115-022-01665-w
21. Zhao, D., Wang, J., Lin, H., Wang, X., Yang, Z., & Zhang, Y. (2021). Biomedical cross-sentence relation extraction via multihead attention and graph convolutional networks. Applied Soft Computing, 104, 107230. https://doi.org/10.1016/j.asoc.2021.107230