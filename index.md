# Capturing Causal Claims: A Fine-Tuned Text Mining Model for Extracting Causal Sentences from Social Science Papers
## Abstract:
**_keywords_**: causal text mining, social science, parameter efficient tuning, causal sentences dataset
## 1. Introduction:
Understanding causality is an integral part of social scientific research. Causality is implicitly assumed when the results of social science research are used to inform decisions in treatment, policy, parenting, or clinical practice (Busetti, 2023). Causal relationships are also crucial from a theoretical point of view, as a hallmark of “strong theories” is that they provide causal explanations for phenomena of interest (Hedström & Ylikoski, 2010). There are growing concerns over a “theory crisis” in the social sciences because many prevailing psychological theories are vague and non-specific with regard to causality, which makes it difficult to formulate testable hypotheses and impedes cumulative knowledge acquisition (Berkman & Wilson, 2021; Sanbonmatsu et al., 2021). Scholars have recognized the importance of developing good theories that go beyond mere descriptions of empirical patterns. Good theories elucidate the underlying causal mechanisms (Reiter, 2017; Van De Ven, 1989). As Pearl (2009) notes, understanding causality enables social scientists, practitioners, consultants, and policy makers to draw meaningful insights from research literature to prescribe empirically supported solutions and interventions. Causal assumptions play a key role in substantiating hypotheses and facilitating nuanced interpretations of findings, thus enriching scholarly discourse (Meehl, 1990; Reiter, 2017). Given the importance of causality, it is unfortunate that social scientists do not always explicitly discuss causality (Gross, 2018). To take stock of the current state of causal thought within a specific body of literature, this paper introduces a text mining model that extracts causal claims from full text papers. By automating the effortful procedure of coding statements as causal versus non-causal, this method enables comprehensive systematic reviews of causal claims in (large) bodies of literature. Our work contributes by curating a tailored dataset for social science literature and fine-tuning a model to extract causal sentences. This approach effectively addresses the challenges posed by the often ambiguous language used in social science literature to express causality, thereby substantially improving the accuracy and reliability of causal claim extraction from scholarly documents.
### 1.1 Why Care About Causality?
Given the importance of causal assumptions for theory and practice, investigating existing causal claims in the published social scientific literature is a promising new area of meta-scientific research. An overview of existing causal claims can inform theory development, justify practical applications, and strengthen the methodological foundations that guide future theory-testing research. Due to the emergence of advanced text mining methods, there has been a recent surge of interest in qualitative (or quantitatively aided qualitative) research synthesis methods. For instance, the use of text mining methods can be used to inductively identify important themes and relationships within a corpus of literature (Van Lissa, 2022). At present, there are some methods available to automatically extract causal claims from scientific text. A major shortcoming of existing techniques is that none have been developed with attention to the idiosyncrasies of social scientific writing.
### 1.2 Prior Work in Causality Detection
Existing techniques for causal claims extraction can be broadly categorized into three main groups: knowledge-based methods, statistical machine learning methods, and deep learning methods (Yang et al., 2022). Knowledge-based methods rely on manually constructed rules, patterns, and domain expertise (Riaz & Girju, 2013). While they are suitable for extracting straightforward causal relationships within single sentences, they require substantial human effort and struggle with implicit or complex cross-sentence causality. To define rules and patterns to recognize the nuanced connections between sentences, these methods must be meticulously crafted, demanding significant time and expertise. As an example of cross-sentence causality, consider the scenario where two distinct causes of divorce are mentioned in separate sentences: "Unfaithfulness is often cited as a leading cause of divorce. Meanwhile, financial stress is identified as another significant contributor." (Yang et al., 2022).

Statistical machine learning methods, leverage natural language processing (NLP) techniques and annotated corpora to extract features, which are then fed into machine learning algorithms. These methods offer more automation than knowledge-based approaches but sometimes  require labor-intensive feature-engineering. The third category, deep learning methods automatically learn condensed numerical representations of words, allowing for better representation learning and cross-domain portability (Yang et al., 2022). Recurrent neural networks (RNNs), convolutional neural networks (CNNs), and graph convolutional networks (GCNs) are among the deep learning models commonly employed for causal relation extraction (Zhao et al., 2021). In the progression of NLP techniques, the advent of BERT (Bidirectional Encoder Representations from Transformers) introduced a paradigm shift towards models equipped with transformer mechanisms. These models, by design, excel in deciphering the context of words within sentences, showcasing a marked improvement over prior methodologies (Kenton & Toutanova, 2019). The advancement of transformer models not only highlights the deficiencies of earlier approaches in understanding language nuances; it has also shown superior performance in benchmark evaluations, surpassing previous knowledge-based and statistical methods in the precision and recall of extracted causal relationships (Tan et al., 2023).

Transformer models are trained on a large corpus of text, and the resulting model is called the pre-trained model. These pre-trained models can then be fine-tuned on specific downstream tasks and datasets. This pre-training feature allows for fine-tuning on specialized tasks using considerably smaller datasets, highlighting their adaptability and effectiveness across a wide range of applications (Chen & Zhang, 2021). However, a notable concern is the substantial computational resources required, which has been somewhat alleviated by emerging techniques such as Parameter-Efficient tuning. This technique optimizes a small portion of model parameters while keeping the rest fixed, significantly reducing computation and storage costs (Ding et al., 2023). This development offers a promising way to harness the computational power of these models more efficiently. Given their profound understanding of context and nuanced capabilities, this study aims to employ transformer’s models to leverage their strengths in addressing challenges posed by limited data resources.


## References

1. Berkman, E. T., & Wilson, S. M. (2021). So useful as a good theory? The practicality crisis in (social) psychological theory. _Perspectives on Psychological Science_, _16_(4), 864–874.

2. Busetti, S. (2023). Causality is good for practice: Policy design and reverse engineering. _Policy Sciences_, _56_(2), 419–438. https://doi.org/10.1007/s11077-023-09493-7

3. Chen, Z., & Zhang, Y. (2021). Better few-shot text classification with pre-trained language model. _Artificial Neural Networks and Machine Learning–ICANN 2021: 30th International Conference on Artificial Neural Networks, Bratislava, Slovakia, September 14–17, 2021, Proceedings, Part II 30_, 537–548.

4. Ding, N., Qin, Y., Yang, G., Wei, F., Yang, Z., Su, Y., Hu, S., Chen, Y., Chan, C.-M., Chen, W., Yi, J., Zhao, W., Wang, X., Liu, Z., Zheng, H.-T., Chen, J., Liu, Y., Tang, J., Li, J., & Sun, M. (2023). Parameter-efficient fine-tuning of large-scale pre-trained language models. _Nature Machine Intelligence_, _5_(3), 220–235. https://doi.org/10.1038/s42256-023-00626-4

5. Gross, N. (2018). The Structure of Causal Chains. _Sociological Theory_, _36_(4), 343–367. https://doi.org/10.1177/0735275118811377

6. Hedström, P., & Ylikoski, P. (2010). Causal Mechanisms in the Social Sciences. _Annual Review of Sociology_, _36_(1), 49–67. https://doi.org/10.1146/annurev.soc.012809.102632

7. Kenton, J. D. M.-W. C., & Toutanova, L. K. (2019). Bert: Pre-training of deep bidirectional transformers for language understanding. _Proceedings of naacL-HLT_, _1_, 2.

8. Meehl, P. E. (1990). Appraising and Amending Theories: The Strategy of Lakatosian Defense and Two Principles that Warrant It. _Psychological Inquiry_, _1_(2), 108–141. https://doi.org/10.1207/s15327965pli0102_1

9. Pearl, J. (2009). _Causal inference in statistics: An overview_.

10. Reiter, B. (2017). _Theory and methodology of exploratory social science research_.

11. Riaz, M., & Girju, R. (2013). Toward a better understanding of causality between verbal events: Extraction and analysis of the causal power of verb-verb associations. _Proceedings of the SIGDIAL 2013 Conference_, 21–30.

12. Sanbonmatsu, D. M., Cooley, E. H., & Butner, J. E. (2021). The Impact of Complexity on Methods and Findings in Psychological Science. _Frontiers in Psychology_, _11_, 580111. https://doi.org/10.3389/fpsyg.2020.580111

13. Tan, F. A., Zuo, X., & Ng, S.-K. (2023). _UniCausal: Unified Benchmark and Repository for Causal Text Mining_ (arXiv:2208.09163). arXiv. http://arxiv.org/abs/2208.09163

14. Van De Ven, A. H. (1989). Nothing Is Quite So Practical as a Good Theory. _Academy of Management Review_, _14_(4), 486–489. https://doi.org/10.5465/amr.1989.4308370

15. Van Lissa, C. J. (2022). Mapping Phenomena Relevant to Adolescent Emotion Regulation: A Text-Mining Systematic Review. _Adolescent Research Review_, _7_(1), 127–139. https://doi.org/10.1007/s40894-021-00160-7

16. Yang, J., Han, S. C., & Poon, J. (2022). A survey on extraction of causal relations from natural language text. _Knowledge and Information Systems_, _64_(5), 1161–1186. https://doi.org/10.1007/s10115-022-01665-w

17. Zhao, D., Wang, J., Lin, H., Wang, X., Yang, Z., & Zhang, Y. (2021). Biomedical cross-sentence relation extraction via multihead attention and graph convolutional networks. _Applied Soft Computing_, _104_, 107230. https://doi.org/10.1016/j.asoc.2021.107230